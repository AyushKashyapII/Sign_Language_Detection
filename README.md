# ğŸ§ ğŸ¤Ÿ Sign Language Detection using ML & Live Camera Feed

This project aims to detect and recognize **American Sign Language (ASL)** hand gestures in real-time using a webcam feed and Machine Learning models. It provides an interactive way to translate hand signs into text, bridging communication gaps for the deaf and hard-of-hearing community.

---

## ğŸ“¸ Demo

> Live hand gesture recognition from webcam, converting signs into readable text on-screen.


## ğŸš€ Features

- Live detection of ASL alphabets using webcam
- Real-time predictions using ML/DL models (like CNN)
- Preprocessing and hand tracking with OpenCV & MediaPipe
- Clean interface with live text output
- Easily extendable to words or custom gestures

---

## ğŸ› ï¸ Tech Stack

- **Python**
- **OpenCV** (Video feed & image preprocessing)
- **MediaPipe** (Hand tracking)
- **NumPy / Pandas / Matplotlib**
- **Jupyter Notebook / Streamlit**

---
